# 
## icu
主页已经到这里
https://gitlab.pyicu.org/main/pyicu

https://github.com/ovalhub/pyicu
https://lib.rs/crates/icu_capi
https://docs.rs/icu/latest/icu/
https://github.com/unicode-org/icu4x/tree/main/ffi/npm

https://gitlab.pyicu.org/main/pyicu
https://github.com/goodsign/icu
这个没有分词的功能

这个只有语言检测功能
https://github.com/aboSamoor/pycld2?tab=readme-ov-file
https://github.com/google/cld3

## 方法二 jieba 加词库

go: jieba up 2.6k
https://github.com/go-ego/gse/blob/master/README_zh.md

泰文字典可以用这个
https://github.com/tlwg/libthai/tree/master/data

https://github.com/PyThaiNLP/pythainlp/blo b/dev/pythainlp/corpus/words_th.txt
https://github.com/PyThaiNLP/pythainlp/tree/dev/pythainlp/corpus
https://github.com/PyThaiNLP/pythainlp

拼音
https://github.com/go-ego/gpy

https://github.com/yanyiwu/gojieba c++ 2.4k
    https://imlht.com/archives/416/

https://github.com/wangbin/jiebago 老版本
"github.com/jaysharp/jiebago" 我们用的

## 方法三： nlp server

https://github.com/web64/nlpserver
python3 -m polyglot download LANG:en？为什么我没有有？

https://github.com/keon/awesome-nlp

https://github.com/jsrpy/Chinese-NLP-Jieba/blob/master/jieba_intro.ipynb

py:
https://github.com/fxsjy/jieba
es thai https://github.com/apachecn/elasticsearch-doc-zh/blob/master/docs/354.md